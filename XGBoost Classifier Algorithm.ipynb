{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XgBoost Model creation\n",
    "def dump_model(model, filename):\n",
    "    \"\"\"\n",
    "    Function store the object data to the file write-binary (wb) mode\n",
    "    \"\"\"\n",
    "    pickle.dump(model, open(filename,\"wb\"))\n",
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Function reads the pickled byte stream object from a file object\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(filename):\n",
    "        return None\n",
    "    return pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "# Model Training Loop\n",
    "def main_loop():\n",
    "    \"\"\"\n",
    "    Created main loop for Xgboost classifier\n",
    "    \"\"\"\n",
    "    train = pd.read_csv(\"data/train.csv\")\n",
    "    test = pd.read_csv(\"data/test.csv\")\n",
    "    # dataset \n",
    "    train_dataset = dataset(train)\n",
    "    test_dataset  = dataset(test)\n",
    "    # dataloader \n",
    "    train_dataloader  =  DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "    test_dataloader   =  DataLoader(test_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", output_hidden_states=True) # 768 * 2\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.require_grads = False\n",
    "    model.to(device)\n",
    "    # XGBoost Classifier\n",
    "    xgb_model = XGBClassifier()\n",
    "    filename_xgboost_model = \"xgb_class.pkl\"\n",
    "    for ep in tqdm(range(100)): #100 iterations\n",
    "        total_loss = 0.0\n",
    "        train_f1 = []\n",
    "        train_acc = []\n",
    "        for idx, data in enumerate(train_dataloader):\n",
    "            if load_model(filename_xgboost_model) != None:\n",
    "                xgb_model = load_model(filename_xgboost_model)\n",
    "\n",
    "            input_ids = data[\"input_ids\"].to(device).squeeze()\n",
    "            attention_mask = data[\"attention_mask\"].to(device).squeeze()\n",
    "            labels = data[\"labels\"].to(device)\n",
    "            outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
    "            embeddings = torch.mean(outputs.hidden_states[-1], dim=1).squeeze()\n",
    "            embeddings = embeddings.detach().cpu().numpy()\n",
    "            gt         = labels.detach().cpu().numpy()\n",
    "            xgb_model.fit(embeddings, gt, verbose=True)\n",
    "            dump_model(xgb_model, filename_xgboost_model)\n",
    "            prediction = xgb_model.predict(embeddings)\n",
    "            predictions = [round(value) for value in prediction]\n",
    "            accuracy = accuracy_score(gt, predictions)\n",
    "            f1Score  = f1_score(gt, predictions)\n",
    "            train_acc.append(accuracy)\n",
    "            train_f1.append(f1Score)\n",
    "            \n",
    "        if ep%20 == 0: # result after every 20 episodes\n",
    "            # Testing purpose\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                total_test_loss = 0.0\n",
    "                test_f1 = []\n",
    "                test_acc =[]\n",
    "\n",
    "                for idx, data in tqdm(enumerate(test_dataloader)):\n",
    "                    input_ids = data[\"input_ids\"].to(device).squeeze()\n",
    "                    attention_mask = data[\"attention_mask\"].to(device).squeeze()\n",
    "                    labels = data[\"labels\"].to(device)\n",
    "                    outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
    "                    embeddings = torch.mean(outputs.hidden_states[-1], dim=1).squeeze()\n",
    "                    embeddings = embeddings.detach().cpu().numpy()\n",
    "                    gt         = labels.detach().cpu().numpy()\n",
    "                    prediction = xgb_model.predict(embeddings)\n",
    "                    predictions = [round(value) for value in prediction]\n",
    "                    accuracy = accuracy_score(gt, predictions)\n",
    "                    f1Score  = f1_score(gt, predictions)\n",
    "                    test_acc.append(accuracy)\n",
    "                    test_f1.append(f1Score)\n",
    "\n",
    "                print(f'Train F1 {np.array(train_f1).mean()} and Test F1 {np.array(test_f1).mean()}')\n",
    "                print(f'Train Accuracy {np.array(train_acc).mean()} and Test Accuracy {np.array(test_acc).mean()}')\n",
    "main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Result\n",
    "# XGBoost Model iteration result/ summary with model f1_score and accuracy \n",
    "\n",
    "# 1%|          | 1/100 [03:40<6:04:24, 220.85s/it]Train F1 1.0 and Test F1 0.8224122351402976\n",
    "# Train Accuracy 1.0 and Test Accuracy 0.8152173913043478\n",
    "# 21%|██        | 21/100 [59:16<3:57:46, 180.59s/it]Train F1 1.0 and Test F1 0.8299674575679544\n",
    "# Train Accuracy 1.0 and Test Accuracy 0.8434103260869565\n",
    "# 41%|████      | 41/100 [1:54:48<2:57:31, 180.54s/it]Train F1 1.0 and Test F1 0.8230136992151285\n",
    "# Train Accuracy 1.0 and Test Accuracy 0.8230298913043478\n",
    "# 61%|██████    | 61/100 [2:50:26<1:57:42, 181.08s/it]Train F1 1.0 and Test F1 0.7743025141140807\n",
    "# Train Accuracy 1.0 and Test Accuracy 0.7800611413043478\n",
    "# 81%|████████  | 81/100 [3:46:05<57:14, 180.74s/it]Train F1 1.0 and Test F1 0.8060651487815814\n",
    "# Train Accuracy 1.0 and Test Accuracy 0.807235054347826"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
